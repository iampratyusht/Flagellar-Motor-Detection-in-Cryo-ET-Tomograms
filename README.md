# ğŸ§  Flagellar Motor Detection in Cryo-ET Tomograms
## ğŸ§¬ Introduction
The **flagellar motor** is a molecular machine that facilitates the motility of many microorganisms, playing a key role in processes ranging from chemotaxis to pathogenesis. 

**Cryogenic Electron Tomography (cryo-ET)** enables the imaging of these nanomachines in near-native conditions. However, identifying flagellar motors in these 3D reconstructions (tomograms) is **labor-intensive**. Challenges include:

- Low signal-to-noise ratio  
- Varying motor orientations  
- Dense intracellular environments  

This bottleneck creates a need for **automated image processing** solutions. This projectâ€”developed for a **scientific competition**â€”aims to automate the identification of flagellar motors using deep learning with the **YOLOv8** object detection framework.

---

## ğŸ“‚ Repository Structure

```

project/
â”œâ”€â”€ visualize.py                 # Script to preview labeled image slices
â”œâ”€â”€ yaml_data_utils.py           # YAML generator for dataset
â”œâ”€â”€ main.py                      # Model loader and training logic
â”‚   â”œâ”€â”€Yolomodelloader
â”‚   â””â”€â”€train_yolo_model
â”œâ”€â”€ inference.py                 # Parallel and dynamic batching inference
â”‚   â”œâ”€â”€GPUProfiler
â”‚   â””â”€â”€test
â”œâ”€â”€ evaluate.py                  # Evaluation + plotting
â”‚   â”œâ”€â”€Evaluatedataset
â”‚   â””â”€â”€evaluate
â”œâ”€â”€ utils.py
â”œâ”€â”€ requirements.txt             # Required Python libraries
â””â”€â”€ README.md                    # You are here

```

---

## ğŸ“ Dataset Structure

Make sure your dataset follows this structure:

```

root_dir\
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ tomo000abc
â”‚   â”‚   â”œâ”€â”€ slice_000.jpg
â”‚   â”‚   â”œâ”€â”€ slice_001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test/
â”‚   â””â”€â”€ tomo000xyz
â”‚       â”œâ”€â”€ slice_000.jpg
â”‚       â”œâ”€â”€ slice_001.jpg
â”‚       â””â”€â”€ ...
â”œâ”€â”€ train_labels.csv


````
Parsed yaml dataset follows this structure:

```

data.yaml
â”œâ”€â”€ images
â”‚   â”œâ”€â”€train
â”‚   â”‚   â”œâ”€â”€ .\path\tomo000abc\slice_0000.jpg
â”‚   â”‚   â”œâ”€â”€ .\path\tomo000abc\slice_0001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€val
â”‚   â”‚   â””â”€â”€ ...
â”œâ”€â”€ labels
â”‚   â”œâ”€â”€train
â”‚   â”‚   â”œâ”€â”€ .\path\tomo000abc\slice_0000.txt
â”‚   â”‚   â”œâ”€â”€ .\path\tomo000abc\slice_0001.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€val/
â”‚   â”‚   â””â”€â”€ ...

````

**Note:**  
- `labels/` must contain YOLO-format `.txt` label files (one per image).  
- `data.yaml` defines the dataset configuration.

---

## âš™ï¸ Installation

Install the required libraries using:

```bash
pip install -r requirements.txt
````

Contents of `requirements.txt`:

```text
ultralytics
torch
torchvision
opencv-python
matplotlib
numpy
```

---

## ğŸ–¼ï¸ Visualize Dataset Images

Preview how YOLO labels align with image slices:

```bash
    python visualise.py --path root_dir --mode random --n 10
    python visualise.py --path root_dir --mode transform --n 5
    python visualise.py --path root_dir --mode slices --n 10
    python visualise.py --path root_dir --mode boxes --n 6 --label_path ./labels.csv
```

---

## ğŸ“„ Generate YOLO `data.yaml`

To auto-generate the `data.yaml` config file:

```bash
python yaml_data_utils.py \
  --root root_dir \
  --yaml_dir dataset_root/data.yaml \
  --window_size 24 \
  --neg_include True\
```

---


## ğŸ§  Train the Model

Run training using your dataset and selected YOLO version:

```bash
python train_model.py \
  --yaml_path dataset_dir/data.yaml \
  --yolo_weights_dir ./weights \
  --evaluate_dir ./eval \
  --root_dir ./dataset_root \
  --model_version yolov8n \
  --epochs 50 \
  --batch_size 16 \
  --img_size 640
```

Trained weights and evaluation plots will be saved under `./weights/motor_detector/` and `./eval`.

---

## ğŸ” Run Inference on Test Data

```bash
python inference.py \
  --model_path ./weights/motor_detector/weights/best.pt \
  --test_dir root_dir/test \
  --submission_path ./submission.csv
```

This script processes slices using **GPU-optimized dynamic batching**.

---

## ğŸ§  Supported YOLO Models

Compatible with all [Ultralytics YOLOv8](https://docs.ultralytics.com) models:

* `yolov8n.pt` â€“ Nano (fastest, lightweight)
* `yolov8s.pt` â€“ Small
* `yolov8m.pt` â€“ Medium
* `yolov8l.pt` â€“ Large (most accurate)

Choose via `--model_version` or use `--model_path` for a custom checkpoint.

---

## ğŸš€ Dynamic Batch Inference + GPU Profiling

The `inference.py` script:

* **Adapts batch size** based on available GPU memory
* Uses **CUDA streams** for parallel sub-batch inference
* Profiles GPU time for performance evaluation

Example (inside `inference.py`):

```python
free_mem = gpu_mem - torch.cuda.memory_allocated(0) / 1e9
BATCH_SIZE = max(8, min(32, int(free_mem * 4)))

streams = [torch.cuda.Stream() for _ in range(min(4, self.batch_size))]
```

---

## ğŸ§ª Evaluation and Plotting

After training, validation loss curves and best epoch information are printed:

```python
best_epoch, best_val_loss = evaluate.plot_loss_curve(run_dir)
```

---

## ğŸ§© Applicability to Other Domains

This pipeline is well-suited for other **3D imaging tasks**, such as:

* ğŸ§  **MRI or CT scan slice detection**
* ğŸ”¬ **Volume electron microscopy**
* ğŸ—ï¸ **Tomographic reconstruction in materials science**

---

## ğŸ“¬ Submitting Predictions

The final predictions are saved to `submission.csv` in the format required by your competition platform or benchmark.

---